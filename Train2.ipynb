{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BASE_DIR = r\"C:\\Project\\Enhanced_Dataset\\dataset\"\n",
    "IMAGE_SIZE = (150, 150)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "CLASSES = ['no', 'sphere', 'vort']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "LEARNING_RATE = 5e-5  # Adjusted for stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(150, scale=(0.7, 1.0)),  # üî• More aggressive cropping\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),  # üî• Increase rotation range\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # üî• Add hue jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),  # üî• Introduce translations\n",
    "    transforms.GaussianBlur(3),  # üî• Simulate telescope noise\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Dataset Class (Handles Corrupted Files)\n",
    "class DarkMatterDataset(Dataset):\n",
    "    def __init__(self, base_dir, mode, transform):\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for label, cls in enumerate(CLASSES):\n",
    "            cls_dir = os.path.join(base_dir, mode, cls)\n",
    "            for img_file in os.listdir(cls_dir):\n",
    "                img_path = os.path.join(cls_dir, img_file)\n",
    "                self.img_paths.append(img_path)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "\n",
    "        try:\n",
    "            img = np.load(img_path)\n",
    "        except Exception as e:\n",
    "            print(f\"üö® ERROR: Skipping corrupted file {img_path} | {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self.img_paths))\n",
    "\n",
    "        img = cv2.resize(img, IMAGE_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        img = np.stack([img] * 3, axis=0).astype(np.float32)\n",
    "\n",
    "        img = self.transform(torch.tensor(img))  # ‚úÖ Transform applied here\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DarkMatterDataset(BASE_DIR, 'train', train_transform)\n",
    "val_dataset = DarkMatterDataset(BASE_DIR, 'val', val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarkMatterClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DarkMatterClassifier, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.resnet.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "            param.requires_grad = True  \n",
    "\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),  # üî• Reduce FC layer size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),  # üî• Increase dropout\n",
    "            nn.Linear(512, num_classes),  # üî• Reduce FC layer size\n",
    "    )\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Instantiate Model\n",
    "model = DarkMatterClassifier(NUM_CLASSES).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desai\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ‚úÖ Loss, Optimizer & Scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Early Stopping Class\n",
    "# class EarlyStopping:\n",
    "#     def __init__(self, patience=3, mode=\"max\", min_delta=0.001):\n",
    "#         self.patience = patience\n",
    "#         self.mode = mode\n",
    "#         self.min_delta = min_delta\n",
    "#         self.best_score = None\n",
    "#         self.counter = 0\n",
    "#         self.early_stop = False\n",
    "\n",
    "#     def __call__(self, score):\n",
    "#         if self.best_score is None:\n",
    "#             self.best_score = score\n",
    "#         elif (self.mode == \"max\" and score < self.best_score + self.min_delta) or \\\n",
    "#              (self.mode == \"min\" and score > self.best_score - self.min_delta):\n",
    "#             self.counter += 1\n",
    "#             if self.counter >= self.patience:\n",
    "#                 self.early_stop = True\n",
    "#         else:\n",
    "#             self.best_score = score\n",
    "#             self.counter = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs):\n",
    "    best_auc = 0.0\n",
    "    patience = 3  # Stop if no improvement for 3 epochs\n",
    "    counter = 0\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        all_labels, all_probs, all_preds = [], [], []\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().detach().numpy()\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "        if len(all_labels) == 0:\n",
    "            print(\"üö® ERROR: No labels collected! Check dataset loading.\")\n",
    "            return  \n",
    "\n",
    "        all_labels = label_binarize(all_labels, classes=[0, 1, 2])\n",
    "\n",
    "        train_acc = accuracy_score(np.argmax(all_labels, axis=1), all_preds)\n",
    "        train_auc = roc_auc_score(all_labels, np.array(all_probs), multi_class='ovr')\n",
    "\n",
    "        # ‚úÖ Validation Phase\n",
    "        model.eval()\n",
    "        val_labels, val_probs = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "\n",
    "                val_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        if len(val_labels) == 0:\n",
    "            print(\"üö® ERROR: No validation labels! Check validation dataset.\")\n",
    "            return  \n",
    "\n",
    "        val_labels = label_binarize(val_labels, classes=[0, 1, 2])\n",
    "        val_auc = roc_auc_score(val_labels, np.array(val_probs), multi_class='ovr')\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "        # ‚úÖ Early Stopping Logic\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            counter = 0  \n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(f\"‚úÖ Best model saved with AUC: {best_auc:.4f}\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"‚ö†Ô∏è No improvement for {counter} epochs.\")\n",
    "            if counter >= patience:\n",
    "                print(\"üöÄ Early stopping activated!\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(val_auc)  # ‚úÖ Fix: Pass validation AUC as metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/2813 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# # ‚úÖ Train the model\n",
    "train_model(model, train_loader, val_loader, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mall_labels\u001b[49m\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), all_preds)\n\u001b[0;32m      2\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m accuracy_score(val_labels\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39margmax(val_probs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] | Train AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_labels' is not defined"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy_score(all_labels.argmax(axis=1), all_preds)\n",
    "val_acc = accuracy_score(val_labels.argmax(axis=1), np.argmax(val_probs, axis=1))\n",
    "\n",
    "print(f\"Epoch [{epoch+1}/{epochs}] | Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import cv2\n",
    "# from PIL import Image\n",
    "# from torchvision import models, transforms\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Configuration\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# BASE_DIR = r\"C:\\Project\\Enhanced_Dataset\\dataset\"\n",
    "# IMAGE_SIZE = (150, 150)\n",
    "# BATCH_SIZE = 128\n",
    "# EPOCHS = 30\n",
    "# CLASSES = ['no', 'sphere', 'vort']\n",
    "# NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "# # ImageNet statistics\n",
    "# RESNET_MEAN = [0.485, 0.456, 0.406]\n",
    "# RESNET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# ### üñºÔ∏è Enhanced Data Loading with Physics-based Augmentation\n",
    "# class DarkMatterDataset(Dataset):\n",
    "#     def __init__(self, base_dir, mode, transform):\n",
    "#         self.img_paths = []\n",
    "#         self.labels = []\n",
    "#         self.transform = transform\n",
    "\n",
    "#         # Class balancing through oversampling\n",
    "#         class_counts = {cls: len(os.listdir(os.path.join(base_dir, mode, cls))) \n",
    "#                         for cls in CLASSES}\n",
    "#         max_count = max(class_counts.values())\n",
    "\n",
    "#         for label, cls in enumerate(CLASSES):\n",
    "#             cls_dir = os.path.join(base_dir, mode, cls)\n",
    "#             files = os.listdir(cls_dir)\n",
    "\n",
    "#             # Oversample minority classes\n",
    "#             if len(files) < max_count:\n",
    "#                 files = np.random.choice(files, size=max_count, replace=True)\n",
    "\n",
    "#             self.img_paths.extend([os.path.join(cls_dir, f) for f in files])\n",
    "#             self.labels.extend([label] * len(files))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.img_paths[idx]\n",
    "#         img = np.load(img_path).astype(np.float32)\n",
    "\n",
    "#         # Normalize the image\n",
    "#         img = np.clip(img, 0, 1)\n",
    "\n",
    "#         # Convert to PIL image\n",
    "#         img = Image.fromarray((img * 255).astype(np.uint8)).convert(\"RGB\")\n",
    "\n",
    "#         # Apply transform\n",
    "#         if self.transform:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "#         return img, label\n",
    "\n",
    "# ### üîÑ Paper-specified Transformations\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize(IMAGE_SIZE),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomRotation(90),\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "#     transforms.GaussianBlur(3, sigma=(0.1, 0.5)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=RESNET_MEAN, std=RESNET_STD)\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize(IMAGE_SIZE),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=RESNET_MEAN, std=RESNET_STD)\n",
    "# ])\n",
    "\n",
    "# ### üß† Enhanced ResNet Model with Channel Adaptation\n",
    "# class DarkMatterClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Channel adapter (learns grayscale‚ÜíRGB mapping)\n",
    "#         self.channel_adapter = nn.Sequential(\n",
    "#             nn.Conv2d(1, 3, kernel_size=7, padding=3),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(3)\n",
    "#         )\n",
    "\n",
    "#         # Pretrained ResNet50\n",
    "#         self.resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "#         # Freezing strategy (unfreeze last 2 stages)\n",
    "#         for name, param in self.resnet.named_parameters():\n",
    "#             if 'layer3' not in name and 'layer4' not in name and 'fc' not in name:\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "#         # Modified classifier head\n",
    "#         in_features = self.resnet.fc.in_features\n",
    "#         self.resnet.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features, 2048),\n",
    "#             nn.GELU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(2048, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.channel_adapter(x)  # Learned channel conversion\n",
    "#         return self.resnet(x)\n",
    "\n",
    "# ### üöÄ Training Infrastructure\n",
    "# def train_model():\n",
    "#     model = DarkMatterClassifier(NUM_CLASSES).to(DEVICE)\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "#     scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer, mode='max', factor=0.2, patience=3, verbose=True\n",
    "#     )\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     # Data loaders\n",
    "#     train_set = DarkMatterDataset(BASE_DIR, 'train', train_transform)\n",
    "#     val_set = DarkMatterDataset(BASE_DIR, 'val', val_transform)\n",
    "\n",
    "#     train_loader = DataLoader(\n",
    "#         train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "#         num_workers=4, pin_memory=torch.cuda.is_available()\n",
    "#     )\n",
    "#     val_loader = DataLoader(\n",
    "#         val_set, batch_size=BATCH_SIZE, num_workers=4,\n",
    "#         pin_memory=torch.cuda.is_available()\n",
    "#     )\n",
    "\n",
    "#     best_auc = 0\n",
    "#     for epoch in range(EPOCHS):\n",
    "#         model.train()\n",
    "#         train_preds, train_labels = [], []\n",
    "\n",
    "#         for images, labels in tqdm(train_loader, desc=f'Train Epoch {epoch+1}'):\n",
    "#             images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             probs = torch.softmax(outputs, dim=1)\n",
    "#             train_preds.append(probs.detach().cpu())\n",
    "#             train_labels.append(labels.cpu())\n",
    "            \n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_preds, val_labels = [], []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in tqdm(val_loader, desc=f'Val Epoch {epoch+1}'):\n",
    "#                 images = images.to(DEVICE)\n",
    "#                 outputs = model(images)\n",
    "\n",
    "#                 val_preds.append(torch.softmax(outputs, dim=1).cpu())\n",
    "#                 val_labels.append(labels.cpu())\n",
    "\n",
    "#         # Save best model\n",
    "#         val_auc = roc_auc_score(val_labels, torch.cat(val_preds).numpy(), multi_class='ovo')\n",
    "#         if val_auc > best_auc:\n",
    "#             best_auc = val_auc\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "#             print(f\"üèÜ New best model saved with AUC: {best_auc:.4f}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import models, transforms\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Configuration\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# BASE_DIR = r\"C:\\Project\\Enhanced_Dataset\\dataset\"\n",
    "# IMAGE_SIZE = (150, 150)\n",
    "# BATCH_SIZE = 64  # Optimized batch size\n",
    "# EPOCHS = 20\n",
    "# CLASSES = ['no', 'sphere', 'vort']\n",
    "# NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "# ### üìä Data Loader with Efficient Preprocessing\n",
    "# class DarkMatterDataset(Dataset):\n",
    "#     def __init__(self, base_dir, mode, transform):\n",
    "#         self.img_paths = []\n",
    "#         self.labels = []\n",
    "#         self.transform = transform\n",
    "\n",
    "#         for label, cls in enumerate(CLASSES):\n",
    "#             cls_dir = os.path.join(base_dir, mode, cls)\n",
    "\n",
    "#             for img_file in os.listdir(cls_dir):\n",
    "#                 img_path = os.path.join(cls_dir, img_file)\n",
    "#                 self.img_paths.append(img_path)\n",
    "#                 self.labels.append(label)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.img_paths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_path = self.img_paths[idx]\n",
    "\n",
    "#         # Lazily load the image\n",
    "#         img = np.load(img_path)\n",
    "\n",
    "#         # Handle incorrect dimensions\n",
    "#         if img.shape != IMAGE_SIZE:\n",
    "#             img = np.resize(img, IMAGE_SIZE)\n",
    "\n",
    "#         # Expand dimensions and convert to 3 channels\n",
    "#         img = np.expand_dims(img, axis=0)\n",
    "#         img = np.repeat(img, 3, axis=0)\n",
    "\n",
    "#         # Convert to float32\n",
    "#         img = img.astype(np.float32) / 255.0\n",
    "\n",
    "#         # Convert to PyTorch tensor\n",
    "#         img = torch.tensor(img, dtype=torch.float32)\n",
    "#         img = self.transform(img)\n",
    "\n",
    "#         label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "#         return img, label\n",
    "\n",
    "\n",
    "# # Image Transformations with Augmentation\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize(IMAGE_SIZE),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(15),\n",
    "#     transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize(IMAGE_SIZE),\n",
    "#     transforms.Normalize((0.5,), (0.5,))\n",
    "# ])\n",
    "\n",
    "# # Dataloaders\n",
    "# train_dataset = DarkMatterDataset(BASE_DIR, 'train', train_transform)\n",
    "# val_dataset = DarkMatterDataset(BASE_DIR, 'val', val_transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# ### üî• **ResNet50 Model with Regularization and Dropout**\n",
    "# class DarkMatterClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(DarkMatterClassifier, self).__init__()\n",
    "        \n",
    "#         # Load pre-trained ResNet50\n",
    "#         self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "#         # Freeze initial layers for transfer learning\n",
    "#         for param in self.resnet.parameters():\n",
    "#             param.requires_grad = False\n",
    "        \n",
    "#         # Modify final layers\n",
    "#         in_features = self.resnet.fc.in_features\n",
    "#         self.resnet.fc = nn.Sequential(\n",
    "#             nn.Linear(in_features, 1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.4),                      # Increased dropout for regularization\n",
    "#             nn.Linear(1024, num_classes)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.resnet(x)\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = DarkMatterClassifier(NUM_CLASSES).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# # Learning rate scheduler\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode='min', factor=0.2, patience=3, verbose=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Force use of NVIDIA GPU\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Send your model and tensors to the GPU\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# def train_model(model, train_loader, val_loader, epochs):\n",
    "#     best_auc = 0.0\n",
    "#     model = model.to(device)\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "        \n",
    "#         all_labels = []\n",
    "#         all_probs = []    # üí° Store probabilities instead of class indices\n",
    "#         all_preds = []\n",
    "        \n",
    "#         for images, labels in train_loader:\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "            \n",
    "#             # Apply softmax to get probabilities\n",
    "#             probs = torch.softmax(outputs, dim=1).detach().cpu().numpy()\n",
    "#             preds = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "#             all_probs.extend(probs)          # ‚úÖ Append probabilities\n",
    "#             all_preds.extend(preds)\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         train_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "#         # üõ†Ô∏è Use raw probabilities for AUC calculation\n",
    "#         train_auc = roc_auc_score(\n",
    "#             all_labels,\n",
    "#             np.array(all_probs),\n",
    "#             multi_class='ovr'\n",
    "#         )\n",
    "\n",
    "#         # ‚úÖ Validation phase\n",
    "#         model.eval()\n",
    "#         val_labels = []\n",
    "#         val_probs = []\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in val_loader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 outputs = model(images)\n",
    "                \n",
    "#                 val_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "#                 val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "#         val_auc = roc_auc_score(\n",
    "#             val_labels,\n",
    "#             np.array(val_probs),\n",
    "#             multi_class='ovr'\n",
    "#         )\n",
    "\n",
    "#         print(f\"Epoch [{epoch+1}/{epochs}] | Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "#         # Save the best model\n",
    "#         if val_auc > best_auc:\n",
    "#             best_auc = val_auc\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#             print(f\"‚úÖ Best model saved with AUC: {best_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# # Train the model\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     for images, labels in train_loader:\n",
    "#         images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.load('C:\\Project\\X_train.npy')\n",
    "# y_train = np.load('C:\\Project\\y_train.npy')\n",
    "# X_val = np.load('C:\\Project\\X_val.npy')\n",
    "# y_val = np.load('C:\\Project\\y_val.npy')\n",
    "\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Dataset Class\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, X, y, transform=None):\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.X)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.X[idx]\n",
    "#         label = self.y[idx]\n",
    "        \n",
    "#         # Convert to tensor and normalize\n",
    "#         image = torch.from_numpy(image).float() / 255.0\n",
    "        \n",
    "#         # Expand grayscale to RGB if needed\n",
    "#         if len(image.shape) == 2:  # (H,W)\n",
    "#             image = image.unsqueeze(0).repeat(3,1,1)  # (3,H,W)\n",
    "#         elif len(image.shape) == 3 and image.shape[0] == 1:  # (1,H,W)\n",
    "#             image = image.repeat(3,1,1)\n",
    "            \n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "            \n",
    "#         return image, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Data Augmentation & Transforms\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomRotation(15),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Create DataLoaders\n",
    "# batch_size = 64\n",
    "# train_dataset = CustomDataset(X_train, y_train, transform=train_transform)\n",
    "# val_dataset = CustomDataset(X_val, y_val, transform=val_transform)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "#                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "#                        shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Model Definition\n",
    "# class CustomResNet(nn.Module):\n",
    "#     def __init__(self, num_classes=3):\n",
    "#         super().__init__()\n",
    "#         # Load pretrained ResNet\n",
    "#         self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "#         # Freeze all layers first\n",
    "#         for param in self.resnet.parameters():\n",
    "#             param.requires_grad = False\n",
    "            \n",
    "#         # Replace final layer\n",
    "#         num_features = self.resnet.fc.in_features\n",
    "#         self.resnet.fc = nn.Sequential(\n",
    "#             nn.Linear(num_features, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(256, num_classes))\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Training Setup\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = CustomResNet(num_classes=3).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Training Loop\n",
    "# def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "#     best_acc = 0.0\n",
    "#     train_losses, val_losses = [], []\n",
    "#     train_accs, val_accs = [], []\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "#         print('-' * 10)\n",
    "        \n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         running_corrects = 0\n",
    "        \n",
    "#         for inputs, labels in tqdm(train_loader):\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             outputs = model(inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "#         epoch_loss = running_loss / len(train_dataset)\n",
    "#         epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "#         train_losses.append(epoch_loss)\n",
    "#         train_accs.append(epoch_acc)\n",
    "        \n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         val_corrects = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for inputs, labels in val_loader:\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "                \n",
    "#                 outputs = model(inputs)\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "#                 val_loss += loss.item() * inputs.size(0)\n",
    "#                 val_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "#         val_loss = val_loss / len(val_dataset)\n",
    "#         val_acc = val_corrects.double() / len(val_dataset)\n",
    "#         val_losses.append(val_loss)\n",
    "#         val_accs.append(val_acc)\n",
    "        \n",
    "#         scheduler.step(val_loss)\n",
    "        \n",
    "#         print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "#         print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "        \n",
    "#         # Save best model\n",
    "#         if val_acc > best_acc:\n",
    "#             best_acc = val_acc\n",
    "#             torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "#     return model, train_losses, val_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 7. Train the model\n",
    "# model, train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "#     model, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
